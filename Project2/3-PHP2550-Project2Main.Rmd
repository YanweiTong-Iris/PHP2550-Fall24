---
title: "Smoking cessation in adults with major depressive disorder (MDD)"
subtitle: "PHP2550 Project 2: A regression analysis"
author: "Yanwei (Iris) Tong"
date: "2024-10-10"
output: 
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
link-citations: yes
header-includes:
  - "\\usepackage{xcolor}"
abstract: |
  **Purpose:** "to examine baseline variables as potential moderators of the effects of behavioral treatment on end-of-treatment (EOT) abstinence and evaluate baseline variables as predictors of abstinence, controlling for behavioral treatment and pharmacotherapy"  
  
  **Methods:**     
  
  **Results and conclusion:**     
  

geometry: margin=1in
fontsize: 10.5pt
csl: american-statistical-association.csl
bibliography: 0-references.bib
---



```{r setup, include=FALSE}
# to prevent scientific notation
options(scipen=999)

# Set up knit environment
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE, 
                      error = FALSE)

# Load necessary packages
library(tidyverse)
library(kableExtra)
library(knitr)
library(ggplot2)
library(gridExtra)
library(grid)
library(naniar)
library(gtsummary)
library(gt)
library(patchwork)
library(stargazer)
library(knitcitations)
library(mosaic)
library(mice)
library(summarytools)
library(npreg)
library(mgcv)
library(glmnet)
library(pROC)
library(MASS)
library(survey)
library(glmulti)
library(leaps)
```

```{r}
# Define data path and import data
data_path = "/Users/yanweitong/Documents/PHP2550-Data/Project2"
data = read.csv(paste0(data_path, "/project2.csv"))

# Data preprocessing
data = data  %>%
  # create race variable
  mutate(race = factor(case_when(
    NHW == 1 ~ "Non-Hispanic white",
    Black == 1 ~ "Black",
    Hisp == 1 ~ "Hispanic",
    TRUE ~ "Other"  # Handle cases where none of the above conditions are met
  ), levels = c("Non-Hispanic white", "Black", "Hispanic", "Other"))) %>%
  # create treatment categories
  mutate(treatment_cat = factor(case_when(BA == 1 & Var == 0 ~ "BASC+placebo",
                                   BA == 0 & Var == 0 ~ "ST+placebo",
                                   BA == 1 & Var == 1 ~ "BASC+varenicline",
                                   BA == 0 & Var == 1 ~ "ST+varenicline"))) %>% 
  # factorize categorical/ordinal variables
  mutate(
    abst = factor(abst),
    Var = factor(Var),
    BA = factor(BA),
    sex_ps = factor(sex_ps),
    ftcd.5.mins = factor(ftcd.5.mins),
    otherdiag = factor(otherdiag),
    antidepmed = factor(antidepmed),
    mde_curr = factor(mde_curr),
    Only.Menthol = factor(Only.Menthol),
    edu = factor(edu, levels = c(1, 2, 3, 4, 5)),
    inc = factor(inc, levels = c(1, 2, 3, 4, 5))
  ) %>%
  # make integers numeric 
  mutate(across(
    .cols = where(is.integer) & !all_of("id"),
    .fns = as.numeric 
  ))
```

## \textcolor{orange}{INTRODUCTION}


Fagerstrom Test for Cigarette Dependence
@hitsman2023efficacy

## \textcolor{orange}{METHODS}

### Data Overview and Imputation

\newpage
\begin{landscape}
```{r}
# for sub-tab purpose
table1_data = data %>%
  mutate(
    Demographics = NA,
    Smoking = NA,
    Psychiatric = NA
  ) %>%
  mutate(edu = factor(edu, levels = c(1, 2, 3, 4, 5),
                 labels = c("Grade school", 
                            "Some high school", 
                            "High school graduate or GED", 
                            "Some college/technical school", 
                            "College graduate")),
    inc = factor(inc, levels = c(1, 2, 3, 4, 5),
                 labels = c("Less than $20,000", 
                            "$20,000–35,000", 
                            "$35,001–50,000", 
                            "$50,001–75,000", 
                            "More than $75,000")))
  
table1_data %>%
  dplyr::select(
    treatment_cat,
    Demographics,
    age_ps,
    sex_ps,
    race,
    inc,
    edu,
    Smoking,
    cpd_ps,
    ftcd_score,
    ftcd.5.mins,
    bdi_score_w00,
    crv_total_pq1,
    hedonsum_n_pq1,
    hedonsum_y_pq1,
    NMR,
    Only.Menthol,
    readiness,
    Psychiatric,
    shaps_score_pq1,
    otherdiag,
    antidepmed,
    mde_curr
  ) %>%
  tbl_summary(
    statistic = list(all_continuous() ~ c("{mean} ({sd})"),
                     all_categorical() ~ "{n} ({p}%)"),
    by = treatment_cat,
    digits = all_continuous() ~ 1,
    missing = "no",
    type = list(
      age_ps ~ "continuous",
      sex_ps ~ "dichotomous",
      race ~ "categorical",
      inc ~ "categorical",
      edu ~ "categorical",
      cpd_ps ~ "continuous", 
      ftcd_score ~ "continuous",
      ftcd.5.mins ~ "dichotomous",
      bdi_score_w00 ~ "continuous",
      crv_total_pq1 ~ "continuous",
      hedonsum_n_pq1 ~ "continuous",
      hedonsum_y_pq1 ~ "continuous",
      NMR ~ "continuous",
      Only.Menthol ~ "dichotomous",
      readiness ~ "continuous",
      shaps_score_pq1 ~ "continuous", 
      otherdiag ~ "dichotomous",
      antidepmed ~ "dichotomous",
      mde_curr ~ "dichotomous"
    ),
    label = list(
      age_ps = "Age (years)",
      sex_ps = "Sex (female)",
      race = "Race",
      inc = "Income",
      edu = "Education",
      cpd_ps = "Cigarettes per day",
      ftcd_score = "FTCD score",
      ftcd.5.mins = "Smoking with 5 mins of waking up (Yes)",
      bdi_score_w00 = "BDI score",
      crv_total_pq1 = "Cigarette reward value",
      hedonsum_n_pq1 = "Pleasurable Events Scale (substitute reinforcers)",
      hedonsum_y_pq1 = "Pleasurable Events Scale (complementary reinforcers)",
      Only.Menthol = "Exclusive mentholated cigarette user (Yes)",
      readiness = "Readiness to quit smoking",
      NMR = "Nicotine Metabolism Ratio",
      shaps_score_pq1 = "Anhedonia", 
      otherdiag = "Other lifetime DSM-5 diagnosis (Yes)",
      antidepmed = "Antidepressant medication (Yes)",
      mde_curr = "Current (and past) MDD vs past MDD only (Yes)"
    ),
    value = list(
      sex_ps ~ "2",
      Only.Menthol ~ "1",
      otherdiag ~ "1",
      antidepmed ~ "1",
      mde_curr ~ "1",
      ftcd.5.mins ~ "1"
    )
  ) %>%
  add_overall() %>%
  modify_header(label ~ "**Characteristic**") %>%
  modify_caption(caption = "Participant characteristics by overall sample and treatment arm") %>%
  # for sub-tab purpose
  modify_table_body(
    ~ .x %>%
      mutate(across(everything(), ~ ifelse(. == "0 (NA%)", "", .)))
  ) %>%  
  modify_table_styling(
    rows = label %in% c("Demographics", "Smoking", "Psychiatric"),
    columns = label,
    text_format = "bold"
  )   %>%
  as_kable_extra(
    booktabs = TRUE,
    longtable = TRUE,
    linesep = "",
    format = "latex"
  ) %>%
  kableExtra::kable_styling(
    position = "center",
    latex_options = c("striped", "repeat_header"),
    stripe_color = "gray!15",
    font_size = 8
  )
```

\end{landscape}
\newpage

```{r}
# Missingness table
# Calculate missing values for each variable
missing_summary <- data %>%
  summarise(across(everything(), ~ sum(is.na(.)), .names = "{col}")) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Number") %>%
  mutate(Pct = (Number / nrow(data)) * 100) %>%
  filter(Number > 0)  # Exclude variables with 0 missingness

# Define a named vector with old and new names for variables
variable_names <- c(
  "inc" = "Income",
  "ftcd_score" = "FTCD score at baseline",
  "crv_total_pq1" = "Cigarette reward value at baseline",
  "shaps_score_pq1" = "Anhedonia",
  "NMR" = "Nicotine Metabolism Ratio",
  "Only.Menthol" = "Exclusive Mentholated Cigarette User",
  "readiness" = "Baseline readiness to quit smoking"
)

# Rename variables in the summary table
missing_summary <- missing_summary %>%
  mutate(Variable = recode(Variable, !!!variable_names))


# Create and display the table
missing_summary %>%
  arrange(desc(Pct)) %>%
  mutate(Pct = sprintf("%.2f%%", Pct)) %>%
  kable(col.names = c("Variable", "Number", "Pct"), 
        caption = "Summary of missing values")
```

```{r}
# Create a new variable that contains the 3 first levels of edu
data <- data %>%
  mutate(edu_merged = factor(case_when(
    edu %in% c("1", "2", "3") ~ "1",
    edu == "4" ~ "2",
    edu == "5" ~ "3"
  )))

```



```{r}
# Create and display the contingency table between race and menthol useage
table_race_menthol <- table(data$race, data$Only.Menthol)

# Perform the chi-square test
chi_square_test <- chisq.test(table_race_menthol)

chi_square_text <- paste0(
  sprintf("Chi-Square Statistic ≈ %.2f", chi_square_test$statistic),
  sprintf("， p-value ≈ %.4f", chi_square_test$p.value)
)

kable(table_race_menthol, 
      caption = "Contingency Table of Race vs. Only Menthol Use with Chi-Square Test Result", 
      col.names = c("Non-Menthol-Only", "Menthol-Only"),
      row.names = TRUE) %>%
   footnote(chi_square_text,
            footnote_as_chunk = FALSE)

```


```{r}
# Perform MICE imputation
data_mice <- mice(data, m = 5, method = "pmm", 
                  maxit = 50, seed = 2024, printFlag = FALSE)

# Complete the data by extracting one of the imputed datasets
data_imp <- complete(data_mice, action = 1) 
```


### Analysis Methods










## \textcolor{orange}{RESULTS}

### Baseline Characteristics as Potential Moderators 
```{r}
# Logistic regression with stepwise selection
# Define the outcome and variables in the model
outcome <- data_imp$abst
variable_names <- c("Var", "BA", "age_ps", "sex_ps", "inc", "edu_merged", "race",
                     "ftcd_score", "ftcd.5.mins", "bdi_score_w00", "cpd_ps",
                     "crv_total_pq1", "hedonsum_n_pq1", "hedonsum_y_pq1",
                     "shaps_score_pq1", "otherdiag", "antidepmed", "mde_curr",
                     "NMR", "Only.Menthol", "readiness")
variables <- data_imp[, variable_names]
# for Lasso (to break down factors with >2 levels)
variables_dummy <- model.matrix(~ 0 + ., data = variables)
# remove the extra reference group
variables_dummy <- variables_dummy[, -which(colnames(variables_dummy) =="Var0")]

# Split into train and test
set.seed(1)
train_index <- sample(1:nrow(data_imp), 0.7 * nrow(data_imp))
train_data <- data_imp[train_index,]
test_data <- data_imp[-train_index,]
train_outcome <- outcome[train_index]
test_outcome <- outcome[-train_index]
# for best subset
train_variables <- variables[train_index, ]
test_variables <- variables[-train_index, ]


# Main effects for `Var` and `BA` (to be considered/controlled in all models)
main_effects <- paste(variable_names, collapse = " + ")

# Define the interaction terms we want to consider
BA_interaction_terms <- 
  paste("BA:Var", #interaction between treatments
        #interaction with demographics
        "BA:age_ps + BA:sex_ps + BA:inc+ BA:edu_merged + BA:race",
        # with smoking
        "BA:ftcd_score + BA:Only.Menthol + BA:NMR+ BA:readiness",
        # with MDD
        "BA:mde_curr + BA:bdi_score_w00 + BA:shaps_score_pq1 + BA:antidepmed",
        "BA:otherdiag + BA:shaps_score_pq1",
        sep = " + ")

other_interaction_terms <- paste(
  # pharmatherapy with demographics
  "Var:age_ps + Var:sex_ps + Var:race + Var:ftcd_score + Var:cpd_ps",
  # between demographics
  "inc:edu_merged",
  # Menthol exclusive with demographics
  "sex_ps:Only.Menthol + race:Only.Menthol + inc:Only.Menthol + edu_merged:Only.Menthol",
  # NMR with demographics, cigarette dependence, and readiness to quit
  "sex_ps:NMR + age_ps:NMR + cpd_ps:NMR + NMR:readiness + ftcd_score:NMR",
  # readiness to quit with cigarette dependence and MDD
  "ftcd_score:readiness + Only.Menthol:readiness + mde_curr:readiness ",
  # cigarette dependence with demographics
  "sex_ps:ftcd_score + race:ftcd_score + age_ps:ftcd_score",
  sep = " + "
)

# Full formula for main effects and interactions
full_formula <- as.formula(paste("abst ~", main_effects, "+", BA_interaction_terms,
                                 "+", other_interaction_terms))

# Define scope with `Var` and `BA` as forced terms in the main model
scope_list <- list(
  lower = as.formula("abst ~ Var + BA"),  # Minimal model with controlled terms
  upper = full_formula                    # Full model with all main and interaction terms
)

# Fit logistic regression model with stepwise selection
set.seed(2024)
stepwise_model <- step(
  glm(formula = abst ~ Var + BA, data = train_data, family = "binomial"),
  scope = scope_list,
  direction = "both",
  trace = 0
)

```



```{r}
# for L0 + L1
train_variables_dummy <- variables_dummy[train_index, ]
test_variables_dummy <- variables_dummy[-train_index, ]

train_data_glmnet = data.frame(abst = train_outcome, train_variables_dummy)
test_data_glmnet = data.frame(abst = test_outcome, test_variables_dummy)

train_bestglm <- data.frame(train_variables, abst = train_outcome)
test_bestglm <- data.frame(test_variables, abst = test_outcome)

# Enforce Var and BA as 0 penalty
# Elastic Net
# ^2 generates all pairwise interactions
train_variables_dummy_df <- as.data.frame(train_variables_dummy)
train_variables_dummy_full_interactions <- model.matrix(~ .^2, 
                                                         data = train_variables_dummy_df)

test_variables_dummy_df <- as.data.frame(test_variables_dummy)
test_variables_dummy_full_interactions <- model.matrix(~ .^2, 
                                                         data = test_variables_dummy_df)

# To identify the potential interaction terms for moderator effects
train_variables_dummy_include_names <- c(
  "Var1", "BA1", "age_ps", "sex_ps2", "inc2", "inc3", 
  "inc4", "inc5", "edu_merged2", "edu_merged3",
  "raceBlack", "raceHispanic", "raceOther", 
  "ftcd_score", "ftcd.5.mins1", "bdi_score_w00", "cpd_ps",
  "crv_total_pq1", "hedonsum_n_pq1", "hedonsum_y_pq1",              
  "shaps_score_pq1", "otherdiag1", "antidepmed1",                  
  "mde_curr1", "NMR", "Only.Menthol1",                 
  "readiness", "Var1:BA1", 
  #Behavioral treatment (MAIN)
  "BA1:mde_curr1", 
  "BA1:age_ps", "BA1:sex_ps2", 
  "BA1:raceBlack", "BA1:raceHispanic",
  "BA1:raceOther", "BA1:ftcd_score", 
  "BA1:shaps_score_pq1","BA1:bdi_score_w00", 
  "BA1:otherdiag1", "BA1:antidepmed1",
  "BA1:mde_curr1","BA1:NMR",
  "BA1:Only.Menthol1", "BA1:readiness",
  # Pharmatherapy
  "Var1:mde_curr1",
  "Var1:age_ps", "Var1:sex_ps2",
  "Var1:raceBlack", "Var1:raceHispanic",
  "Var1:raceOther", "Var1:ftcd_score", 
  # Income*Edu
  "inc2:edu_merged2", "inc2:edu_merged3", 
  "inc3:edu_merged2", "inc3:edu_merged3", 
  "inc4:edu_merged2", "inc4:edu_merged3", 
  "inc5:edu_merged2", "inc5:edu_merged3", 
  # Readiness to quit
  "Only.Menthol1:readiness", 
  "mde_curr1:readiness", "ftcd_score:readiness", 
  # FTCD Score 
  "sex_ps2:ftcd_score", "raceBlack:ftcd_score", 
  "raceHispanic:ftcd_score", "raceOther:ftcd_score", 
  "age_ps:ftcd_score", 
  # Menthol exclusive
  "sex_ps2:Only.Menthol1", "raceBlack:Only.Menthol1", 
  "raceHispanic:Only.Menthol1", "raceOther:Only.Menthol1", 
  "inc2:Only.Menthol1", "inc3:Only.Menthol1", 
  "inc4:Only.Menthol1", "inc5:Only.Menthol1", 
  "edu_merged2:Only.Menthol1", "edu_merged3:Only.Menthol1", 
  # NMR
  "sex_ps2:NMR", "age_ps:NMR", "cpd_ps:NMR", 
  "NMR:readiness", "ftcd_score:NMR"
)

train_variables_dummy_include = 
  train_variables_dummy_full_interactions[,train_variables_dummy_include_names]
test_variables_dummy_include = 
  test_variables_dummy_full_interactions[,train_variables_dummy_include_names]

# Set penalty factors to enforce keeping Var and BA
# Initialize penalty factors to 1 for all variables
penalty_factors <- rep(1, ncol(train_variables_dummy_include))

# Identify columns corresponding exactly to "Var1" and "BA1" (not their interactions)
var1_col <- grep("^Var1$", colnames(train_variables_dummy_include))
ba1_col <- grep("^BA1$", colnames(train_variables_dummy_include))

penalty_factors[c(var1_col, ba1_col)] <- 0
names(penalty_factors) <- colnames(train_variables_dummy_include)
```



```{r}
# Fit Elastic Net
set.seed(2024)
enet_model <- cv.glmnet(as.matrix(train_variables_dummy_include), train_outcome,
                         penalty.factor = penalty_factors,
                         alpha = 0.5, family = "binomial")

# Extract coefficients at the optimal lambda (best_lambda)
best_lambda_enet <- enet_model$lambda.min
#remove intercept
optimal_coefs_enet <- as.numeric(coef(enet_model, s = best_lambda_enet)[-1])
coef_names_enet <- rownames(coef(enet_model, s = best_lambda_enet))[-1]  

result_table_enet <- data.frame(
  variable = coef_names_enet,
  Coefficient = optimal_coefs_enet
) %>%
  filter(Coefficient != 0) 
```


```{r}
set.seed(2024)
regsubsets_model <-
    regsubsets(y = train_outcome,
               x = train_variables_dummy_include,
               nbest = 1,       # 1 best model for each number of predictors
               nvmax = 20,    
               force.in = c("Var1", "BA1"),
               force.out = NULL,
               really.big = T,
               method = "seqrep")

reg_summary = summary(regsubsets_model)
cp_min = which.min(reg_summary$cp)
best_subset_coefs = coef(regsubsets_model, cp_min)
best_subset_names = names(coef(regsubsets_model, cp_min))
```



```{r}
# Summary table of coef
# Stepwise coefficients
stepwise_coefs <- coef(stepwise_model)
stepwise_df <- data.frame(
  variable = names(stepwise_coefs),
  `Stepwise` = as.numeric(stepwise_coefs)
)

# ENET coefficients 
enet_df <- result_table_enet %>%
  rename(`Elastic Net` = Coefficient)

# Best subset coefficients
best_subset_df <- data.frame(
  variable = names(best_subset_coefs),
  `Best Subset` = as.numeric(best_subset_coefs)
)

# Merge all into one table based on variable names
combined_df <- full_join(stepwise_df, enet_df, by = "variable") %>%
  full_join(best_subset_df, by = "variable") %>%
  mutate(across(where(is.numeric), ~ round(.x, 4)))

# Remove the intercept row
combined_df <- combined_df[combined_df$variable != "(Intercept)", ]

colnames(combined_df) <- gsub("Best.Subset", "Best Subset", colnames(combined_df))
```

```{r}
combined_df <- combined_df %>%
  mutate(
    variable = sapply(variable, function(x) {
      # Split each interaction term into components
      terms <- unlist(strsplit(x, ":"))
      # Sort alphabetically and rejoin with ":"
      if (length(terms) > 1) {
        paste(sort(terms), collapse = ":")
      } else {
        x  # If not an interaction term, keep it as is
      }
    })
  )

combined_df <- combined_df %>%
  mutate(across(c(Stepwise, `Elastic Net`, `Best Subset`), 
                ~ as.numeric(as.character(.))))


# Combine rows with the same standardized interaction term names
# Summing the coefficients for duplicate terms (or use mean instead if averaging is preferred)
combined_df <- combined_df %>%
  group_by(variable) %>%
  summarize(across(c(`Stepwise`, `Elastic Net`, `Best Subset`), sum, na.rm = TRUE)) %>%
  ungroup()

# Replace NA values with an empty space
combined_df <- combined_df %>%
  mutate(across(c(Stepwise, `Elastic Net`, `Best Subset`), ~ ifelse(. == 0, " ", .)))


# Display the final combined table
kable(combined_df, row.names = F,
      caption = "Summary of Coefficients for Moderator Effects across 3 Selection Methods")
```


```{r}
predicted_prob_stepwise <- predict(stepwise_model,
                                newdata = test_data,
                                type = "response")

# Convert predictions to numeric if needed (glmnet returns a matrix)
predicted_prob_stepwise <- as.numeric(predicted_prob_stepwise)

# Plot ROC and calculate AUC
# Generate ROC object
roc_stepwise <- roc(test_outcome, predicted_prob_stepwise)

# Convert the ROC object to a data frame for ggplot2
roc_data <- data.frame(
  Specificity = rev(roc_stepwise$specificities),
  Sensitivity = rev(roc_stepwise$sensitivities)
)

# Calculate the AUC
auc_value <- auc(roc_stepwise)

# Plot ROC curve with ggplot2
ROC_stepwise = ggplot(roc_data, aes(x = 1-Specificity, y = Sensitivity)) +
  geom_line(color = "black", size = 1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
  annotate("text", x = 0.8, y = 0.2, 
           label = paste("AUC =", round(auc_value, 2)), size = 5, color = "Black") +
  labs(
    x = "1 - Specificity",
    y = "Sensitivity"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5))
```

```{r, fig.width = 12, fig.height = 4}
num_cuts <- 10  # Number of bins for calibration

calib_data <- data.frame(
  prob = predicted_prob_stepwise,  # predicted probabilities
  # binning into `num_cuts` groups
  bin = cut(predicted_prob_stepwise, breaks = num_cuts),  
  # observed values (abst outcome in test data)
  class = as.numeric(test_outcome)-1  
)

calib_data <- calib_data %>%
  group_by(bin) %>%
  summarise(
    observed = mean(class),  
    predicted = mean(prob),  
    se = sqrt(observed * (1 - observed) / n())  # Standard error
  )

# Add Loess Fit for Flexible Calibration Line
loess_fit <- loess(observed ~ predicted, data = calib_data, span = 0.75)
calib_data$loess_pred <- predict(loess_fit, calib_data$predicted)

# Plot Calibration Curve with Error Bars
calib_error_bar_stepwise = ggplot(calib_data) + 
  geom_abline(intercept = 0, slope = 1, color = "red") + 
  geom_errorbar(aes(x = predicted, ymin = observed - 1.96 * se, 
                    ymax = observed + 1.96 * se), 
                colour="black", width=.01)+
  geom_point(aes(x = predicted, y = observed)) +
  labs(x = "Expected Probability of Smoking Abstinence", 
       y = "Actual Smoking Abstinence") +
  theme_minimal()


# Plot Calibration Curve with Loess
calib_data <- calib_data %>%
  mutate(loess_ci_lower = loess_pred - 1.96 * sd(loess_pred),
         loess_ci_upper = loess_pred + 1.96 * sd(loess_pred))

calib_loess_stepwise = ggplot(calib_data, aes(x = predicted, y = observed)) +
  # Flexible calibration (Loess)
  geom_line(aes(y = loess_pred), color = "blue", linetype = "dashed") +  
  geom_ribbon(aes(ymin = loess_ci_lower, ymax = loess_ci_upper), alpha = 0.2, fill = "grey") +
  geom_abline(intercept = 0, slope = 1, color = "red") +  # Perfect calibration line
  labs(x = "Predicted Probability of Smoking Abstinence", 
       y = "Actual Smoking Abstinence") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

```{r}
predicted_prob_enet <- predict(enet_model, 
                                newx = as.matrix(test_variables_dummy_include), 
                                s = "lambda.min", type = "response")

# Convert predictions to numeric if needed (glmnet returns a matrix)
predicted_prob_enet <- as.numeric(predicted_prob_enet)

# Plot ROC curve and calculate AUC
# Generate ROC object
roc_enet <- roc(test_outcome_numeric, predicted_prob_enet)

# Convert the ROC object to a data frame for ggplot2
roc_data <- data.frame(
  Specificity = rev(roc_enet$specificities),
  Sensitivity = rev(roc_enet$sensitivities)
)

# Calculate the AUC
auc_value <- auc(roc_enet)

# Plot ROC curve with ggplot2
ROC_enet = ggplot(roc_data, aes(x = 1-Specificity, y = Sensitivity)) +
  geom_line(color = "black", size = 1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
  annotate("text", x = 0.8, y = 0.2, label = paste("AUC =", round(auc_value, 2)), size = 5, color = "Black") +
  labs(
    x = "1 - Specificity",
    y = "Sensitivity"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5))
```

```{r}
num_cuts <- 10  # Number of bins for calibration

calib_data <- data.frame(
  prob = predicted_prob_enet,  # predicted probabilities
  # binning into `num_cuts` groups
  bin = cut(predicted_prob_enet, breaks = num_cuts),  
  # observed values (abst outcome in test data)
  class = as.numeric(test_outcome)-1  
)

calib_data <- calib_data %>%
  group_by(bin) %>%
  summarise(
    observed = mean(class),  
    predicted = mean(prob),  
    se = sqrt(observed * (1 - observed) / n())  # Standard error
  )

# Add Loess Fit for Flexible Calibration Line
loess_fit <- loess(observed ~ predicted, data = calib_data, span = 0.75)
calib_data$loess_pred <- predict(loess_fit, calib_data$predicted)

# Plot Calibration Curve with Error Bars
calib_error_bar_enet = ggplot(calib_data) + 
  geom_abline(intercept = 0, slope = 1, color = "red") + 
  geom_errorbar(aes(x = predicted, ymin = observed - 1.96 * se, 
                    ymax = observed + 1.96 * se), 
                colour="black", width=.01)+
  geom_point(aes(x = predicted, y = observed)) +
  labs(x = "Expected Probability of Smoking Abstinence", 
       y = "Actual Smoking Abstinence") +
  #       title = "Calibration Plot for Elastic Net Model with Error Bars"
  theme_minimal()


# Plot Calibration Curve with Loess
calib_data <- calib_data %>%
  mutate(loess_ci_lower = loess_pred - 1.96 * sd(loess_pred),
         loess_ci_upper = loess_pred + 1.96 * sd(loess_pred))

calib_loess_enet = ggplot(calib_data, aes(x = predicted, y = observed)) +
  # Flexible calibration (Loess)
  geom_line(aes(y = loess_pred), color = "blue", linetype = "dashed") +  
  geom_ribbon(aes(ymin = loess_ci_lower, ymax = loess_ci_upper), alpha = 0.2, fill = "grey") +
  geom_abline(intercept = 0, slope = 1, color = "red") +  # Perfect calibration line
  scale_color_manual(values = c("Ideal" = "red", 
                                "Flexible calibration" = "blue")) +
  scale_linetype_manual(values = c("Ideal" = "solid", 
                                   "Flexible calibration" = "dashed")) +
  labs(x = "Predicted Probability of Smoking Abstinence", 
       y = "Actual Smoking Abstinence",
       color = "Legend", linetype = "Legend") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) 

```

```{r}
predict_best_subset <- function(test_data = test_variables_dummy_include, 
                                best_subset_coefs) {
  intercept <- best_subset_coefs[1]
  selected_vars <- names(best_subset_coefs)[-1] 
  
  test_subset <- test_data[, selected_vars, drop = FALSE]  
  
  # Calculate predictions by multiplying test data with coefficients
  # Matrix multiplication for predictors + intercept
  predictions <- intercept + as.matrix(test_subset) %*% best_subset_coefs[selected_vars]
  
  return(predictions)
}

predicted_prob_best_subset <- predict_best_subset(test_data = test_variables_dummy_include, 
                                   best_subset_coefs)
# Convert predictions to numeric 
predicted_prob_best_subset <- as.numeric(predicted_prob_best_subset) -1

# Plot ROC and calculate AUC
# Generate ROC object
roc_best_subset <- roc(test_outcome, predicted_prob_best_subset)

# Convert the ROC object to a data frame for ggplot2
roc_data <- data.frame(
  Specificity = rev(roc_best_subset$specificities),
  Sensitivity = rev(roc_best_subset$sensitivities)
)

# Calculate the AUC
auc_value <- auc(roc_best_subset)

# Plot ROC curve with ggplot2
ROC_best_subset = ggplot(roc_data, aes(x = 1-Specificity, y = Sensitivity)) +
  geom_line(color = "black", size = 1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +
  annotate("text", x = 0.8, y = 0.2, 
           label = paste("AUC =", round(auc_value, 2)), size = 5, color = "Black") +
  labs(
    x = "1 - Specificity",
    y = "Sensitivity"
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5))
```

```{r}
num_cuts <- 10  # Number of bins for calibration

calib_data <- data.frame(
  prob = predicted_prob_best_subset,  # predicted probabilities
  # binning into `num_cuts` groups
  bin = cut(predicted_prob_best_subset, breaks = num_cuts),  
  # observed values (abst outcome in test data)
  class = as.numeric(test_outcome)-1  
)

calib_data <- calib_data %>%
  group_by(bin) %>%
  summarise(
    observed = mean(class),  
    predicted = mean(prob),  
    se = sqrt(observed * (1 - observed) / n())  # Standard error
  )

# Add Loess Fit for Flexible Calibration Line
loess_fit <- loess(observed ~ predicted, data = calib_data, span = 0.75)
calib_data$loess_pred <- predict(loess_fit, calib_data$predicted)

# Plot Calibration Curve with Error Bars
calib_error_bar_best_subset = ggplot(calib_data) + 
  geom_abline(intercept = 0, slope = 1, color = "red") + 
  geom_errorbar(aes(x = predicted, ymin = observed - 1.96 * se, 
                    ymax = observed + 1.96 * se), 
                colour="black", width=.01)+
  geom_point(aes(x = predicted, y = observed)) +
  labs(x = "Expected Probability of Smoking Abstinence", 
       y = "Actual Smoking Abstinence") +
  theme_minimal()


# Plot Calibration Curve with Loess
calib_data <- calib_data %>%
  mutate(loess_ci_lower = loess_pred - 1.96 * sd(loess_pred),
         loess_ci_upper = loess_pred + 1.96 * sd(loess_pred))

calib_loess_best_subset = ggplot(calib_data, aes(x = predicted, y = observed)) +
  # Flexible calibration (Loess)
  geom_line(aes(y = loess_pred), color = "blue", linetype = "dashed") +  
  geom_ribbon(aes(ymin = loess_ci_lower, ymax = loess_ci_upper), alpha = 0.2, fill = "grey") +
  geom_abline(intercept = 0, slope = 1, color = "red") +  # Perfect calibration line
  labs(x = "Predicted Probability of Smoking Abstinence", 
       y = "Actual Smoking Abstinence") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))

```

```{r, fig.width = 8, fig.height = 8}
plots_stepwise = arrangeGrob(
  calib_error_bar_stepwise, calib_loess_stepwise, ROC_stepwise,
  ncol = 3,
  top = textGrob("Stepwise Selection",
                 gp = gpar(fontface = "bold", fontsize = 13)
))

plots_enet = arrangeGrob(
  calib_error_bar_enet, calib_loess_enet, ROC_enet,
  ncol = 3,
  top = textGrob("Elastic Net",
                 gp = gpar(fontface = "bold", fontsize = 13)
))

plots_best_subset = arrangeGrob(
  calib_error_bar_best_subset, calib_loess_best_subset, ROC_best_subset,
  ncol = 3,
  top = textGrob("Best Subset Selection", 
                 gp = gpar(fontface = "bold", fontsize = 13)
))

# Bold the main title
main_title <- textGrob(
  "Figure 1: Calibration Plots with Error Bars and LOESS and ROC Curves for 3 Selection Models",
  gp = gpar(fontsize = 16) 
)

# Arrange everything with the bold title
grid.arrange(
  plots_stepwise,
  plots_enet,
  plots_best_subset,
  nrow = 3,
  top = main_title
)
```

```{r}
test_outcome_numeric = as.numeric(test_outcome) - 1

# Calculate Brier Score for each model
brier_stepwise <- mean((predicted_prob_stepwise - test_outcome_numeric)^2)
brier_enet <- mean((predicted_prob_enet - test_outcome_numeric)^2)
brier_best_subset <- mean((predicted_prob_best_subset - test_outcome_numeric)^2)


# calibration error
ce_calculate <- function(predictions, actuals, n_bins = 10) {
  bins <- cut(predictions, breaks = seq(0, 1, length.out = n_bins + 1), include.lowest = TRUE)
  bin_means <- tapply(predictions, bins, mean)
  print(bin_means)
  bin_actuals <- tapply(actuals, bins, mean)
  bin_weights <- table(bins) / length(predictions)
  ce <- sum(bin_weights * abs(bin_means - bin_actuals))
  
  # Remove NA values from bin_means and bin_actuals
  valid_bins <- !is.na(bin_means) & !is.na(bin_actuals)
  bin_means <- bin_means[valid_bins]
  bin_actuals <- bin_actuals[valid_bins]
  bin_weights <- bin_weights[valid_bins]
  
  # Calculate ECE with valid bins only
  CE <- sum(bin_weights * abs(bin_means - bin_actuals))
  
  return(CE)
}

CE_stepwise <- ce_calculate(predicted_prob_stepwise, test_outcome_numeric)
CE_enet <- ce_calculate(predicted_prob_enet, test_outcome_numeric)
CE_best_subset <- ce_calculate(predicted_prob_best_subset, test_outcome_numeric)


# Calculate AUC for each model
auc_stepwise <- roc_stepwise$auc
auc_enet <- roc_enet$auc
auc_best_subset <- roc_best_subset$auc

# Get optimal threshold, specificity, and sensitivity for each model
threshold_stepwise <- as.numeric(coords(roc_stepwise, "best", 
                                        ret = "threshold"))
specificity_stepwise <- as.numeric(coords(roc_stepwise, "best", 
                                          ret = "specificity"))
sensitivity_stepwise <- as.numeric(coords(roc_stepwise, "best", 
                                          ret = "sensitivity"))

threshold_enet <- as.numeric(coords(roc_enet, "best", 
                                    ret = "threshold"))
specificity_enet <- as.numeric(coords(roc_enet, "best", 
                                      ret = "specificity"))
sensitivity_enet <- as.numeric(coords(roc_enet, "best", 
                                      ret = "sensitivity"))

threshold_best_subset <- as.numeric(coords(roc_best_subset, "best", 
                                           ret = "threshold"))
specificity_best_subset <- as.numeric(coords(roc_best_subset, "best", 
                                             ret = "specificity"))
sensitivity_best_subset <- as.numeric(coords(roc_best_subset, "best", 
                                             ret = "sensitivity"))

# Combine metrics into a table
df_performance <- rbind(
  Brier = round(c(brier_stepwise, brier_enet, brier_best_subset), 4),
  `Calibration error` = round(c(ce_stepwise, ce_enet, ce_best_subset), 4),
  AUC = round(c(auc_stepwise, auc_enet, auc_best_subset), 4),
  Threshold = round(c(threshold_stepwise, threshold_enet, threshold_best_subset), 4),
  Specificity = round(c(specificity_stepwise, specificity_enet, specificity_best_subset), 4),
  Sensitivity = round(c(sensitivity_stepwise, sensitivity_enet, sensitivity_best_subset), 4)
  #`Adjusted R^2` = round(c(adj_r2_stepwise, adj_r2_enet, adj_r2_best_subset), 4)
)

# rename columns
colnames(df_performance) <- c("Stepwise", "Elastic Net", "Best Subset")

# Display the final table
kable(
  df_performance, 
  caption = "Calibration and Discrimination Metrics for 
  Stepwise, Elastic Net, and Best Subset Models"
)
```


### Baseline Characteristics as Potential Predictors
```{r}
predictor_names <- c("Var", "BA", "age_ps", "sex_ps", "inc", "edu_merged", "race",
                     "ftcd_score", "ftcd.5.mins", "bdi_score_w00", "cpd_ps",
                     "crv_total_pq1", "hedonsum_n_pq1", "hedonsum_y_pq1",
                     "shaps_score_pq1", "otherdiag", "antidepmed", "mde_curr",
                     "NMR", "Only.Menthol", "readiness")
predictors <- data_imp[, predictor_names]
# for Lasso (to break down factors with >2 levels)
predictors_dummy <- model.matrix(~ 0 + ., data = predictors)
# remove the extra reference group
predictors_dummy <- predictors_dummy[, -which(colnames(predictors_dummy) =="Var0")]


# Full formula for main effects and interactions
full_formula <- as.formula(paste("abst ~", main_effects))

# Define scope with `Var` and `BA` as forced terms in the main model
scope_list <- list(
  lower = as.formula("abst ~ Var + BA"),  # Minimal model with controlled terms
  upper = full_formula                    # Full model with all main terms
)

# Fit logistic regression model with stepwise selection
set.seed(2024)
predictor_stepwise_model <- step(
  glm(formula = abst ~ Var + BA, data = train_data, family = "binomial"),
  scope = scope_list,
  direction = "both",
  trace = 0
)
```

```{r}
# Fit Elastic Net
# To identify the potential interaction terms for moderator effects
train_predictors_dummy_include_names <- c(
  "Var1", "BA1", "age_ps", "sex_ps2", "inc2", "inc3",
  "inc4", "inc5", "edu_merged2", "edu_merged3",
  "raceBlack", "raceHispanic", "raceOther",
  "ftcd_score", "ftcd.5.mins1", "bdi_score_w00", "cpd_ps",
  "crv_total_pq1", "hedonsum_n_pq1", "hedonsum_y_pq1",
  "shaps_score_pq1", "otherdiag1", "antidepmed1",
  "mde_curr1", "NMR", "Only.Menthol1",
  "readiness"
)

train_predictors_dummy <- predictors_dummy[train_index, ]
test_predictors_dummy <- predictors_dummy[-train_index, ]

train_predictors_dummy_include = 
  train_predictors_dummy[,train_predictors_dummy_include_names]
test_predictors_dummy_include = 
  test_variables_dummy[,train_predictors_dummy_include_names]

# Set penalty factors to enforce keeping Var and BA
# Initialize penalty factors to 1 for all variables
penalty_factors <- rep(1, ncol(train_predictors_dummy_include))

# Identify columns corresponding exactly to "Var1" and "BA1" (not their interactions)
var1_col <- grep("^Var1$", colnames(train_predictors_dummy_include))
ba1_col <- grep("^BA1$", colnames(train_predictors_dummy_include))

penalty_factors[c(var1_col, ba1_col)] <- 0
names(penalty_factors) <- colnames(train_predictors_dummy_include)


set.seed(2024)
predictor_enet_model <- cv.glmnet(as.matrix(train_predictors_dummy_include), 
                                  train_outcome,
                         penalty.factor = penalty_factors,
                         alpha = 0.5, family = "binomial")

# Extract coefficients at the optimal lambda (best_lambda)
best_lambda_enet <- predictor_enet_model$lambda.min
#remove intercept
optimal_coefs_enet <- as.numeric(coef(predictor_enet_model, s = best_lambda_enet)[-1])
coef_names_enet <- rownames(coef(predictor_enet_model, s = best_lambda_enet))[-1]

predictor_result_table_enet <- data.frame(
  variable = coef_names_enet,
  Coefficient = optimal_coefs_enet
) %>%
  filter(Coefficient != 0)
```

```{r}
set.seed(2024)
predictor_regsubsets_model <-
    regsubsets(y = train_outcome,
               x = train_predictors_dummy_include,
               nbest = 1,       # 1 best model for each number of predictors
               nvmax = 20,    
               force.in = c("Var1", "BA1"),
               force.out = NULL,
               really.big = T,
               method = "exhaustive")

predictor_reg_summary = summary(predictor_regsubsets_model)
cp_min = which.min(reg_summary$cp)
predictor_best_subset_coefs = coef(predictor_regsubsets_model, cp_min)
predictor_best_subset_names = names(coef(predictor_regsubsets_model, cp_min))

```


```{r}
# Summary table of coef
# Stepwise coefficients
stepwise_coefs <- coef(predictor_stepwise_model)
stepwise_df <- data.frame(
  variable = names(stepwise_coefs),
  `Stepwise` = as.numeric(stepwise_coefs)
)

# ENET coefficients 
enet_df <- predictor_result_table_enet %>%
  rename(`Elastic Net` = Coefficient)

# Best subset coefficients
best_subset_df <- data.frame(
  variable = names(predictor_best_subset_coefs),
  `Best Subset` = as.numeric(predictor_best_subset_coefs)
)

# Merge all into one table based on variable names
combined_df <- full_join(stepwise_df, enet_df, by = "variable") %>%
  full_join(best_subset_df, by = "variable") %>%
  mutate(across(where(is.numeric), ~ round(.x, 4)))

# Remove the intercept row
combined_df <- combined_df[combined_df$variable != "(Intercept)", ]

# Replace NA values with an empty space
combined_df[is.na(combined_df)] <- " "

colnames(combined_df) <- gsub("Best.Subset", "Best Subset", colnames(combined_df))

# Display the final combined table
kable(combined_df, row.names = F,
      caption = "Summary of Coefficients for Predictor Effects across 3 Selection Methods")
```


## \textcolor{orange}{CONCLUSION}

## \textcolor{orange}{LIMITATIONS}

## Consent, Data, and Code Availability

Primary data were provided by Dr. George Papandonatos from the Department of Biostatistics at Brown University. The original data cannot be shared directly for privacy. Replication scripts are available at <https://github.com/YanweiTong-Iris/PHP2550-Fall24/tree/main/Project2>.

# Reference
<div id="refs"></div>


\pagebreak

# Figure Appendix

\pagebreak

# Code Appendix

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```
