---
title: "TBD"
subtitle: "PHP2550 Project 3: A simulation study"
author: "Yanwei (Iris) Tong"
date: "2024-11-12"
output: 
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
    #number_sections: true
link-citations: yes
header-includes:
  - "\\usepackage{xcolor}"
  - "\\usepackage{amsmath}"
abstract: |
  **Purpose:** 
  
  **Methods**:     
  
  **Results and conclusion**: 
  

geometry: margin=1in
fontsize: 10.5pt
---

```{r setup, include=FALSE}
# to prevent scientific notation
options(scipen=999)

# Set up knit environment
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE, 
                      warning = FALSE, 
                      error = FALSE)

# Load necessary packages
library(tidyverse)
library(kableExtra)
library(knitr)
library(ggplot2)
library(gridExtra)
library(grid)
library(naniar)
library(gtsummary)
library(gt)
library(patchwork)
library(knitcitations)
library(glmnet)
library(pROC)
library(MASS)
library(leaps)
library(RColorBrewer) 
library(cowplot)
library(lme4)
library(doParallel)
library(foreach)


# Define data saving paths
data_path = paste0(here::here(), "/Project3/simulated_data")
result_path = paste0(here::here(), "/Project3/results")
```

# \textcolor{orange}{INTRODUCTION}

# \textcolor{orange}{SIMULATION DESIGN}

## Aims and Objectives

**Aim 1**: To evaluate the impact of different design choices (number of clusters $G$ and observations per cluster $R$) under budget constraints $B$.

**Aim 2**: To explore the relationships between the underlying data generation mechanism parameters (e.g., variance components) and cost structure (relative costs $c_1/c_2$) and their impacts on estimation efficiency of treatment effects.

**Aim 3**: To compare performance under different outcome distributions (Normal vs. Poisson).

## Data Generating Mechanisms

#### Cost constraint

$$
c_1 + G(R-1)c_2 \leq B
$$

#### Hierarchical Model for Normal Outcomes

1.  **Cluster-level mean:**

$$
\mu_{i0} = \alpha + \beta X_i \quad (\text{fixed effect for treatment/control groups}) \\
\mu_i \mid \epsilon_i = \mu_{i0} + \epsilon_i, \quad \epsilon_i \sim N(0, \gamma^2) \\
\mu_i \sim N(\mu_{i0}, \gamma^2)
$$

2.  **Observation-level outcomes:**

$$
Y_{ij} \mid \mu_i = \mu_i + e_{ij}, \quad e_{ij} \sim N(0, \sigma^2)\\
Y_{ij} \mid \mu_i \sim N(\mu_i, \sigma^2)$$

3.  **Marginal outcome distribution:**
$$\text{Marginal mean:} \quad \mathbb{E}[Y\_{ij} \mid X_i] = \alpha + \beta X_i \\
\text{Marginal variance:} \quad \text{Var}(Y\_{ij} \mid X_i) = \gamma^2 + \sigma^2 $$

#### Hierarchical Model for Poisson Outcomes

1.  **Cluster-level mean:**
$$
\log(\mu_i) = \alpha + \beta X_i + \epsilon_i, \quad \epsilon_i \sim N(0, \gamma^2)\\
\mu_i \sim \text{LogNormal}(\alpha + \beta X_i, \gamma^2)
$$

2.  **Observation-level outcomes:** 
$$
    Y_{ij} \mid \mu_i \sim \text{Poisson}(\mu_i)
$$

3.  **Summing within a cluster:** 
$$
Y_i = \sum_{j=1}^R Y_{ij} \quad (\text{sum of all observations in the cluster}) 
$$ 
$$
Y_i \mid \mu_i \sim \text{Poisson}(R \mu_i)
$$



```{r}
#' @param alpha Intercept parameter (baseline mean).
#' @param beta Treatment effect.
#' @param gamma_sq Variance of cluster-level random effects.
#' @param sigma_sq Variance of observation-level random noise.
#' @param B Total budget available for the study (in dollars).
#' @param c1 Cost of the first sample in each cluster.
#' @param c2 Cost of additional samples in the same cluster (c2 < c1).
#' @param G Number of clusters
#' @param R Number of observations per cluster
#' @param n_sim Number of simulation iterations for tracking purposes
#' @return Data frame containing simulated data (Y, X) and the input parameters.
#' @export
simulate_clustered_data <- function(dist = "Normal",
                                    alpha,
                                    beta,
                                    gamma_sq,
                                    sigma_sq,
                                    B,
                                    c1,
                                    c2,
                                    G,
                                    R,
                                    n_sim = 1) {
  
  X <- rbinom(G, size = 1, prob = 0.5)
  epsilon <- rnorm(G, mean = 0, sd = sqrt(gamma_sq))
  
  Y_list <- list()
  cluster_id <- c()
  observation_id <- c()
  n_sim_id <- c()
  
  for (i in 1:G) {
    mu_i <- alpha + beta * X[i] + epsilon[i]
    e_ij <- rnorm(R, mean = 0, sd = sqrt(sigma_sq))
    Y_ij <- mu_i + e_ij
    
    Y_list[[i]] <- Y_ij
    cluster_id <- c(cluster_id, rep(i, R))
    observation_id <- c(observation_id, 1:R)
    n_sim_id <- c(n_sim_id, rep(n_sim, R))
  }
  
  Y <- unlist(Y_list)
  X_obs <- rep(X, each = R)
  data <- data.frame(Y, X_obs, cluster_id, observation_id, n_sim = n_sim_id)
  return(data)
}


#' Find optimal G and R to minimize variance
#'
#' @param alpha Intercept parameter (baseline mean).
#' @param beta Treatment effect.
#' @param gamma_sq Variance of cluster-level random effects.
#' @param sigma_sq Variance of observation-level random noise.
#' @param B Total budget available for the study (in dollars).
#' @param c1 Cost of the first sample in each cluster.
#' @param c2 Cost of additional samples in the same cluster (c2 < c1).
#' @param n_simulations Number of simulations to run for each G and R combination.
#' @print List with optimal G, optimal R, and minimum variance.
#' @return The result dataset with mean and var of Beta_hat for all G and R combination
#' @export
find_optimal_G_R <- function(dist = "Normal", alpha, beta, gamma_sq, sigma_sq, B, c1, c2, n_simulations = 100) {
  min_variance <- Inf
  best_G <- 0
  best_R <- 0
  
  results <- data.frame(alpha = numeric(), beta = numeric(), 
                        gamma_sq = numeric(), sigma_sq = numeric(), 
                        B = numeric(), c1 = numeric(), c2 = numeric(),
                        G = integer(), R = integer(), 
                        betahat = numeric(), variance = numeric())
  
  for (G in 2:(floor((B / c1)) - 1)) {
    R = floor((B - G * c1) / (c2 * G)) + 1
    if (R > 1) {
      betahats <- numeric(n_simulations)
      
      data_list <- list()
      
      set.seed(46)
      for (sim in 1:n_simulations) {
        data <- simulate_clustered_data(dist = "Normal", 
                                        alpha, beta, 
                                        gamma_sq, sigma_sq, 
                                        B, c1, c2, 
                                        G, R, n_sim = sim)
        
        model <- lmer(Y ~ X_obs + (1 | cluster_id), data = data)
        betahats[sim] <- fixef(model)["X_obs"]
        data_list[[sim]] <- data
      }
      
      # Combine all simulated datasets for this G and R combination
      combined_data <- do.call(rbind, data_list)
      
      saveRDS(combined_data, paste0(data_path, 
                                    "/", dist, "_beta_", beta, "_gammasq_", gamma_sq, 
                                    "_sigmasq_", sigma_sq,
                                    "_B_", B, "_c1_", c1, "_c2_", c2,
                                    "/simulated_data_G_", G, "_R_", R, ".rds"))
      
      # Remove NA values from betahats
      betahats <- betahats[!is.na(betahats)]
      
      betahat_mean <- mean(betahats)
      betahat_variance <- var(betahats)
      

    if (betahat_variance < min_variance) {
        min_variance <- betahat_variance
        best_G <- G
        best_R <- R
      }
    
    results <- rbind(
      results,
      data.frame(
        alpha = alpha,
        beta = beta,
        gamma_sq = gamma_sq,
        sigma_sq = sigma_sq,
        B = B,
        c1 = c1,
        c2 = c2,
        G = G,
        R = R,
        betahat_mean = betahat_mean,
        betahat_var = betahat_variance
      )
    )
  }}
  
  write.csv(
    results,
    paste0(
      result_path, 
      "/simulation_results_", dist, "_beta_", beta, "_gammasq_", gamma_sq, 
      "_sigmasq_", sigma_sq,"_B_", B, "_c1_", c1, "_c2_", c2, ".csv"
    ),
    row.names = FALSE
  )
  return(results)
  # cat("Minimum betahat variance:", min_variance, "\n")
  # cat("Optimal number of clusters (G):", best_G, "\n")
  # cat("Optimal number of observations per cluster (R):", best_R, "\n")
}


#' Make the point plot for Var(Betahat) vs. G
#'
#' @param result The result dataset
#' @param group_name For faceted plotting purpose
#' @print The point plot with Var(Betahat) vs G.
var_vs_G_plot_by_facet <- function(results, group_name) {
  
  # Filter results for the specified group
  group_results <- results %>% filter(group == group_name)
  
  # Find the point with the lowest betahat_var for each unique combination of c1 and c2
  lowest_points <- group_results %>%
    group_by(c1, c2) %>%
    filter(betahat_var == min(betahat_var)) %>%
    ungroup()
  
  beta = unique(group_results[["beta"]])
  B = unique(group_results[["B"]])
  c1 = unique(group_results[["c1"]])
  c2 = unique(group_results[["c2"]])
  gamma_sq = unique(group_results[["gamma_sq"]])
  sigma_sq = unique(group_results[["sigma_sq"]])
  
  # Create the faceted plot
  plot = ggplot(group_results, aes(x = G, y = betahat_var)) +
    geom_line(color = "darkblue") +
    geom_point(color = "darkblue") +
    geom_point(data = lowest_points, aes(x = G, y = betahat_var), color = "red", size = 2) +
    geom_text(data = lowest_points, aes(x = G, y = betahat_var, 
                                        label = paste("Min. var =", round(betahat_var, 2), 
                                                      "\n at G =", G, ", R =", R)), 
              vjust = -1.1, hjust = 0.75 ,color = "red", size = 3) +
    labs(
      title = paste("Relationship between Variance of the Beta Estimate and the Number of Clusters"),
      subtitle = bquote(list(B ==.(B), gamma^2 == .(gamma_sq), sigma_^2 == .(sigma_sq), beta ==.(beta))),
      x = " G: Number of Clusters",
      y = "Var(Betahat)"
    ) +
    facet_wrap(~ facet_label,
               scales = "free_x") +
    theme_minimal()
  
  print(plot)
}
```


```{r, fig.width = 10, fig.height = 4, message = F, warning = F}
alpha_list <- rep(4, 12)
beta_list <- c(2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2)
gamma_sq_list <- c(1, 1, 1, 0.58, 0.58, 0.58, 1, 1, 1, 0.58, 0.58, 0.58)
sigma_sq_list <- c(1, 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 4)
B_list <- c(3000, 3000, 3000, 2000, 2000, 2000, 5000, 5000, 5000, 4000, 4000, 4000)
c1_list <- c(100, 50, 50, 100, 50, 50, 100, 50, 50, 100, 50, 50)
c2_list <- c(5, 5, 10, 5, 5, 10, 5, 5, 10, 5, 5, 10)

# num_cores <- parallel::detectCores() - 2
# registerDoParallel(num_cores)

results_list <- list()

for (i in 1:12){
#foreach (i = 1:9, .packages = c("lme4")) %dopar%{
  alpha = alpha_list[i]
  beta = beta_list[[i]]
  gamma_sq = gamma_sq_list[i]
  sigma_sq = sigma_sq_list[i]
  B = B_list[i]
  c1 = c1_list[i]
  c2 = c2_list[i]
  result <- find_optimal_G_R(dist = "Normal", alpha = alpha, beta = beta, 
                             gamma_sq = gamma_sq, sigma_sq = sigma_sq, 
                             B = B, c1 = c1, c2 = c2,
                             # !!!!!!!!
                             n_simulations = 10)
  
  # Add the group to the result for plotting
  result$group <- paste0("Group ", ceiling(i / 3))
  
  # Combine c1 and c2 to create a single label for facetting
  result$facet_label <- paste0("c1 = ", c1, " and c2 = ", c2)
  
  # Store the result in the list
  results_list[[i]] <- result
}

combined_results <- do.call(rbind, results_list)
var_vs_G_plot_by_facet(combined_results, group_name = "Group 1")

#stopCluster(num_cores)
```

```{r, fig.width = 10, fig.height = 4, message = F, warning = F}
var_vs_G_plot_by_facet(combined_results, group_name = "Group 2")
```


```{r, fig.width = 10, fig.height = 4, message = F, warning = F}
var_vs_G_plot_by_facet(combined_results, group_name = "Group 3")
```

```{r, fig.width = 10, fig.height = 4, message = F, warning = F}
var_vs_G_plot_by_facet(combined_results, group_name = "Group 4")
```


## Estimands

## Methods to Evaluate

## Performance Measures

# \textcolor{orange}{RESULTS}

# \textcolor{orange}{CONCLUSION}

# \textcolor{orange}{LIMITATIONS}

# Data, and Code Availability

This project is a collaboration with Dr. Zhijin Wu in the Biostatistics Department. Replication scripts and simulated data are available at <https://github.com/YanweiTong-Iris/PHP2550-Fall24/tree/main/Project2>.

# Reference

\pagebreak

# Code Appendix

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```
